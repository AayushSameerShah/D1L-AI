{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4cadb2",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# File I/O\n",
    "\n",
    "So far we have discussed how to process data and how\n",
    "to build, train, and test deep learning models.\n",
    "However, at some point we will hopefully be happy enough\n",
    "with the learned models that we will want\n",
    "to save the results for later use in various contexts\n",
    "(perhaps even to make predictions in deployment).\n",
    "Additionally, when running a long training process,\n",
    "the best practice is to periodically save intermediate results (checkpointing)\n",
    "to ensure that we do not lose several days' worth of computation\n",
    "if we trip over the power cord of our server.\n",
    "Thus it is time to learn how to load and store\n",
    "both individual weight vectors and entire models.\n",
    "This section addresses both issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dff9f92",
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2d6c9",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## **Loading and Saving Tensors**\n",
    "\n",
    "For individual tensors, we can directly\n",
    "invoke the `load` and `save` functions\n",
    "to read and write them respectively.\n",
    "Both functions require that we supply a name,\n",
    "and `save` requires as input the variable to be saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c45edb",
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, './saves/x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4cdfe",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "We can now read the data from the stored file back into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb11ed0",
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('./saves/x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f40d8",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "We can [**store a list of tensors and read them back into memory.**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dba6ad",
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'./saves/x-files')\n",
    "x2, y2 = torch.load('./saves/x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03e08f",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "We can even [**write and read a dictionary that maps\n",
    "from strings to tensors.**]\n",
    "This is convenient when we want\n",
    "to read or write all the weights in a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8f14c8",
   "metadata": {
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, './saves/mydict')\n",
    "mydict2 = torch.load('./saves/mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f21d5a",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## **Loading and Saving Model Parameters**\n",
    "\n",
    "Saving individual weight vectors (or other tensors) is useful,\n",
    "but it gets very tedious if we want to save\n",
    "(and later load) an entire model.\n",
    "After all, we might have hundreds of\n",
    "parameter groups sprinkled throughout.\n",
    "For this reason the deep learning framework provides built-in functionalities\n",
    "to load and save entire networks.\n",
    "\n",
    "> An important detail to note is that this\n",
    "saves model *parameters* and not the entire model.\n",
    "For example, if we have a 3-layer MLP,\n",
    "we need to specify the architecture separately.\n",
    "\n",
    "\n",
    "The reason for this is that the models themselves can contain arbitrary code,\n",
    "hence they cannot be serialized as naturally.\n",
    "Thus, in order to reinstate a model, we need\n",
    "to generate the architecture in code\n",
    "and then load the parameters from disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6917c6ad",
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# See, that this is the simple MODEL. We will do some crazy stuff later.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75757d4c-9df1-4027-ad65-6a266260d55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8c85c1-c5a5-4e3d-bb59-ae1439a44273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hidden.weight', torch.Size([256, 20])),\n",
       " ('hidden.bias', torch.Size([256])),\n",
       " ('output.weight', torch.Size([10, 256])),\n",
       " ('output.bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88dfe184",
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "### \n",
    "#\n",
    "# THIS IS THE MAIN CODE\n",
    "#\n",
    "###\n",
    "torch.save(net.state_dict(), './saves/mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae860f-3d05-470a-8638-169290fab041",
   "metadata": {},
   "source": [
    "> ### ðŸ’­\n",
    "> See that the `torch.save` can save any python object as a file, just like the pickle. The reason we are storing the `.state_dict()` is because later we will use the `load_state_dict()` to load the weights... there we will need the weights stored in **some specific format**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcdcbd",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "To recover the model, we instantiate a clone\n",
    "of the original MLP model.\n",
    "Instead of randomly initializing the model parameters,\n",
    "we [**read the parameters stored in the file directly**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8e9c03",
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('./saves/mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b209774",
   "metadata": {
    "origin_pos": 41
   },
   "source": [
    "Since both instances have the same model parameters,\n",
    "the computational result of the same input `X` should be the same.\n",
    "Let's verify this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65ae251",
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a1a9f",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "## Summary\n",
    "\n",
    "The `save` and `load` functions can be used to perform file I/O for tensor objects.\n",
    "We can save and load the entire sets of parameters for a network via a parameter dictionary.\n",
    "Saving the architecture has to be done in code rather than in parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4dce94b-65a3-4282-9d2b-bb4f9193b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426d7ef-11e2-4d62-a590-4e94350a3a73",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Even if there is no need to deploy trained models to a different device, what are the practical benefits of storing model parameters?\n",
    "    - Storing the model parameters allows to further train the model in the future from that *checkpoint* rather than training from scratch.\n",
    "    - Even if you are not deploying, it is always a best practice to keep the model parameters somewhere stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3671871-08f1-4f87-b697-993b9a698109",
   "metadata": {},
   "source": [
    "2. Assume that we want to reuse only parts of a network to be incorporated into a network having a different architecture. How would you go about using, say the first two layers from a previous network in a new network?\n",
    "    - Well, this will be an interesting exercise. I would like to tackle this into some combinations.\n",
    "  \n",
    "**<u>We will try the following:</u>**\n",
    "\n",
    "ðŸ”¥ We will try to use the parameters of the model - 1 in the model - 2 which has **entirely different** architecture. \n",
    "\n",
    "ðŸ”¥ We will use partial model - 1's parameters in the model - 2 in which the model - 2 has some similar parameters to the model - 1.\n",
    "\n",
    "ðŸ”¥ All number of weights are the same, just model-2 doesn't have the bias term.\n",
    "\n",
    "Let's see how that goes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388360d3-0571-4735-b5ea-095c2f367076",
   "metadata": {},
   "source": [
    "<img src=\"../images/different-models.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc91c3-6c68-4337-9b62-3a6cc3f1b76c",
   "metadata": {},
   "source": [
    "### Test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc3709c-9d69-4f9c-92b9-382a17633842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different architecture\n",
    "class MODEL_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "Model_1_net = MODEL_1()\n",
    "Model_1_X = torch.randn(size=(2, 5))\n",
    "Model_1_Y = Model_1_net(Model_1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048cc753-4f46-432d-924a-8e07b0073869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the model - 1\n",
    "class MODEL_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(X)\n",
    "\n",
    "Model_2_net = MODEL_2()\n",
    "Model_2_X = torch.randn(size=(2, 5))\n",
    "Model_2_Y = Model_1_net(Model_2_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d32979-0f12-433d-beb2-5e443fdac167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.1612,  0.0042, -0.4217, -0.2391,  0.1241],\n",
       "                      [-0.3142,  0.2413, -0.0544, -0.3145,  0.2827],\n",
       "                      [ 0.0352,  0.1620, -0.0823, -0.1796, -0.1256]])),\n",
       "             ('net.0.bias', tensor([ 0.2893,  0.4079, -0.4366])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[ 0.1933,  0.3769, -0.1508],\n",
       "                      [ 0.2927, -0.3656,  0.5275],\n",
       "                      [-0.0374, -0.1061,  0.1082],\n",
       "                      [-0.0833,  0.3725, -0.0442]])),\n",
       "             ('net.2.bias', tensor([ 0.3388, -0.5125,  0.1416,  0.0006])),\n",
       "             ('net.4.weight', tensor([[ 0.0488, -0.0071, -0.1935,  0.4220]])),\n",
       "             ('net.4.bias', tensor([0.2392]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing directly\n",
    "Model_1_net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be67cd8b-afcb-4273-9ec2-30a8737c2ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.1612,  0.0042, -0.4217, -0.2391,  0.1241],\n",
       "                      [-0.3142,  0.2413, -0.0544, -0.3145,  0.2827],\n",
       "                      [ 0.0352,  0.1620, -0.0823, -0.1796, -0.1256]])),\n",
       "             ('0.bias', tensor([ 0.2893,  0.4079, -0.4366])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.1933,  0.3769, -0.1508],\n",
       "                      [ 0.2927, -0.3656,  0.5275],\n",
       "                      [-0.0374, -0.1061,  0.1082],\n",
       "                      [-0.0833,  0.3725, -0.0442]])),\n",
       "             ('2.bias', tensor([ 0.3388, -0.5125,  0.1416,  0.0006])),\n",
       "             ('4.weight', tensor([[ 0.0488, -0.0071, -0.1935,  0.4220]])),\n",
       "             ('4.bias', tensor([0.2392]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing the network's dict\n",
    "Model_1_net.net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "072acf32-3097-4a20-a229-04c383b1a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model - 1 (in 2 ways)\n",
    "torch.save(Model_1_net.state_dict(), \"./saves/test_1_model_1_direct\")\n",
    "torch.save(Model_1_net.net.state_dict(), \"./saves/test_1_model_1_specific\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675de20-1e1a-4d90-89ea-1e140bdf899d",
   "metadata": {},
   "source": [
    "#### The direct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20bff1f4-9da9-4fb5-89c4-9e21caa8eebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_loading = MODEL_1()\n",
    "model_1_loading.load_state_dict(torch.load('./saves/test_1_model_1_direct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c40497c-02f2-43a2-a3fd-8a734cdf8509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER LOADING, ALL WEIGHTS ARE THE SAME\n",
    "torch.allclose(Model_1_net.net[0].weight, model_1_loading.net[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb6d95-94ab-4232-bd1a-842471003c77",
   "metadata": {},
   "source": [
    "#### The \"specific\" way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3457bcb3-9ae3-427c-9899-9701961bbff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MODEL_1:\n\tMissing key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\", \"net.4.weight\", \"net.4.bias\". \n\tUnexpected key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\", \"4.weight\", \"4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Error(s) in loading state_dict for MODEL_1:\n\tMissing key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\", \"net.4.weight\", \"net.4.bias\". \n\tUnexpected key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\", \"4.weight\", \"4.bias\". \n"
     ]
    }
   ],
   "source": [
    "model_1_loading = MODEL_1()\n",
    "model_1_loading.load_state_dict(torch.load('./saves/test_1_model_1_specific'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da699b7-8872-42bd-b01a-c66ee30d7667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER LOADING, ALL WEIGHTS ARE THE SAME\n",
    "torch.allclose(Model_1_net.net[0].weight, model_1_loading.net[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d5753-88b0-4df3-a3d2-86a2ba7aa06e",
   "metadata": {},
   "source": [
    "> The model above was **just initialized** and the weights were not loaded. Thus, it is giving the `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53827b9f-2035-488a-bfc4-f03ccf480fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_loading = MODEL_1()\n",
    "model_1_loading.net.load_state_dict(torch.load('./saves/test_1_model_1_specific'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d72e604b-1d4d-446a-9b77-d9e6b41b65a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER LOADING, ALL WEIGHTS ARE THE SAME\n",
    "torch.allclose(Model_1_net.net[0].weight, model_1_loading.net[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1fac4-b152-433a-9bfb-4a6e60a42a65",
   "metadata": {},
   "source": [
    "> Viola!!\n",
    "> See? How I used `.net.load_state_dict`? It just works.\n",
    ">\n",
    "> The summary is: **You have to load in the same way you have saved**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8de251-3b9f-48e6-ae89-f781bb8da0b7",
   "metadata": {},
   "source": [
    "### Loading in the Model - 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41c2b4ff-d60c-487e-b634-7ecd39189433",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.4.weight\", \"net.4.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([3, 5]) from checkpoint, the shape in current model is torch.Size([4, 3]).\n\tsize mismatch for net.0.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for net.2.weight: copying a param with shape torch.Size([4, 3]) from checkpoint, the shape in current model is torch.Size([1, 4]).\n\tsize mismatch for net.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.4.weight\", \"net.4.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([3, 5]) from checkpoint, the shape in current model is torch.Size([4, 3]).\n\tsize mismatch for net.0.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for net.2.weight: copying a param with shape torch.Size([4, 3]) from checkpoint, the shape in current model is torch.Size([1, 4]).\n\tsize mismatch for net.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1]).\n"
     ]
    }
   ],
   "source": [
    "model_2_loading = MODEL_2()\n",
    "model_2_loading.load_state_dict(torch.load('./saves/test_1_model_1_direct'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898657c2-400f-41eb-8b19-ff8380345e01",
   "metadata": {},
   "source": [
    "## Test - 2: Same architecture but singe layer is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a670ea-db05-4459-a054-329969e92d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different architecture\n",
    "class MODEL_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2) # from output 1 to 2\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4cd79f-9f8f-4b3c-9d84-2d6e3ead9431",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MODEL_2:\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([1, 4]) from checkpoint, the shape in current model is torch.Size([2, 4]).\n\tsize mismatch for net.4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Error(s) in loading state_dict for MODEL_2:\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([1, 4]) from checkpoint, the shape in current model is torch.Size([2, 4]).\n\tsize mismatch for net.4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n"
     ]
    }
   ],
   "source": [
    "model_2_loading = MODEL_2()\n",
    "model_2_loading.load_state_dict(torch.load('./saves/test_1_model_1_direct'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf17df-ba45-41d1-befa-1a213e3583de",
   "metadata": {},
   "source": [
    "## Test - 3: No bias term in the second model -- other things same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf74cfcf-ce9f-4611-bdc8-8ff55d126178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different architecture\n",
    "class MODEL_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 3, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e660eff-1ac6-40da-88de-5f30951a75a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.0.bias\", \"net.2.bias\", \"net.4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.0.bias\", \"net.2.bias\", \"net.4.bias\". \n"
     ]
    }
   ],
   "source": [
    "model_2_loading = MODEL_2()\n",
    "model_2_loading.load_state_dict(torch.load('./saves/test_1_model_1_direct'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46502e5-a4db-4077-b1ee-beb74be19de2",
   "metadata": {},
   "source": [
    "> Cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e459867-57f6-4156-90d8-619b32ed2374",
   "metadata": {},
   "source": [
    "## Bonus... partially loading the model.\n",
    "\n",
    "<img src=\"../images/partially-matching-models.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d2b38cd-69a0-4e76-aab5-2777cf73a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different architecture. -- but a layer has same one!\n",
    "class MODEL_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 3, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2d21d5e-d16e-4451-bb31-04b52e6736e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.0.bias\", \"net.2.bias\", \"net.4.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([3, 5]) from checkpoint, the shape in current model is torch.Size([3, 2]).\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([1, 4]) from checkpoint, the shape in current model is torch.Size([2, 4]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Error(s) in loading state_dict for MODEL_2:\n\tUnexpected key(s) in state_dict: \"net.0.bias\", \"net.2.bias\", \"net.4.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([3, 5]) from checkpoint, the shape in current model is torch.Size([3, 2]).\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([1, 4]) from checkpoint, the shape in current model is torch.Size([2, 4]).\n"
     ]
    }
   ],
   "source": [
    "model_2_loading = MODEL_2()\n",
    "model_2_loading.load_state_dict(torch.load('./saves/test_1_model_1_direct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21cff033-e4f4-4395-ae8d-236e1a8e6c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(Model_1_net.net[2].weight, model_2_loading.net[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31498160-8987-43da-98bf-3a48b4a5e59c",
   "metadata": {},
   "source": [
    "Look at this!? It **partially loads** what it can!\n",
    "\n",
    "But we can make it run like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49d681a8-9533-4132-b7de-e79075474ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.load('./saves/test_1_model_1_direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "853e9c03-bc05-44b6-a580-ec3bae5a0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['net.0.weight', 'net.0.bias', 'net.2.weight', 'net.2.bias', 'net.4.weight', 'net.4.bias'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fe7dceb-5f82-4bbb-80aa-a126a8ff25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_to_use = layer[\"net.2.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63e9e339-441d-42c2-85cb-ed632a554791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_loading.net.data = weights_to_use.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2600e54-d76c-4a1d-81e8-cc6e94f7ea8e",
   "metadata": {},
   "source": [
    "ðŸ”¥ WOO!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
