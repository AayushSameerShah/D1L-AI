{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dceeda-0cc6-46df-baeb-a98bffdb25e1",
   "metadata": {},
   "source": [
    "#  First time, will use the laptop's stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f53d8f7-f6c5-4cee-9b12-7cf2bf29078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf61dac-68d5-4b1d-8f74-4b87bf84dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b39a5ed-c580-4c4e-8f3a-deaad901a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu(): \n",
    "    \"\"\"Get the CPU device.\"\"\" \n",
    "    return torch.device('cpu')\n",
    "\n",
    "def gpu(i=0): \n",
    "    \"\"\"Get a GPU device.\"\"\" \n",
    "    return torch.device(f'cuda:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbeaa928-c928-4232-96b1-ce6e5ad25d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9f2209-0ea2-4a2d-b6c9-395064755b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af98e384-f61e-4ed5-b11b-56a6745d8127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002bd90-7e17-41c5-ad84-d0b8c4bd747b",
   "metadata": {},
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7821cf-1f99-440c-9040-93bcc9d7f92f",
   "metadata": {},
   "source": [
    "Query the number of GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abbd33b-a516-4648-9eee-9049940d145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_gpus(): #@save \n",
    "    \"\"\"Get the number of available GPUs.\"\"\" \n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "num_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed552b1b-62d7-419a-8de9-948c8736898c",
   "metadata": {},
   "source": [
    "Fucker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c260a36d-0b92-41b2-bfe8-7752bdbb7f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # Should output the CUDA version PyTorch uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17775ed-3d44-4135-8e89-aa0df37e6aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f9e5fa-3383-4fed-92e9-c168cc811c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Wed_Oct_30_01:18:48_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.85\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc8aae4-0ad4-4f53-8f7e-c72a52a2cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # Check PyTorch version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2cdb81-2442-4117-a773-2a1bf372739e",
   "metadata": {},
   "source": [
    "## Let's keep going..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86da819-83e8-48f9-b1c5-75d8419f995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(10), nn.ReLU(), nn.LazyLinear(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1398105-fe9c-4b84-ab4b-8a34c6362554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Assuming `net` is your model\n",
    "device = next(net.parameters()).device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a87bba5-51c6-481c-b12a-ce7b5e4bc5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): LazyLinear(in_features=0, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64483fa6-aa28-42b7-a3fd-1ab635c30aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Assuming `net` is your model\n",
    "device = next(net.parameters()).device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c663476-8293-41d8-b0bd-46f42d86b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making some random data\n",
    "X = torch.rand(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb1087f-0377-4551-86aa-e12bfe81436c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRuntimeError\u001b[0m\u001b[1;31m:\u001b[0m Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n"
     ]
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84672784-ff96-4a48-acb1-11f4b160629f",
   "metadata": {},
   "source": [
    "> Yeah! We need to move the X to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43a0535-4d5a-40e3-98bf-d92444551c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7221c6d1-ca54-4aba-a716-13ec2f5ab9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1350],\n",
       "        [0.1888]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55725201-d2de-490e-a570-18c0a3fc6bde",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e4be86f-8d1f-4bab-9f2b-23154a671740",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X_GPU = torch.rand(n, n, device=\"cuda\")\n",
    "Y_GPU = torch.rand(n, n, device=\"cuda\")\n",
    "\n",
    "X_CPU = torch.rand(n, n, device=\"cpu\")\n",
    "Y_CPU = torch.rand(n, n, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "495f419a-1e2b-49da-b6ad-6ba44ed21911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 µs ± 34.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X_GPU @ Y_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a69caa63-99fa-4a00-8ded-e6ed49518cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.45 ms ± 457 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "X_CPU @ Y_CPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
